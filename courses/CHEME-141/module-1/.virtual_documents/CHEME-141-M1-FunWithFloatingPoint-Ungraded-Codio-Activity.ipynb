





x = 141.72 |> Float32; # why do we need |> Float32?





typeof(x) == Float32 # if Float32, this should be true





d = let

    # initialize -
    bitpattern_dictionary = Dict{Int64,Int64}(); # storage for the 0-based bit pattern
    wordsize = 32; # how many boxes do we have?
    a = bitstring(x) |> reverse |> collect .|> v-> parse(Int64, v) # fancy. Nothing to see here, move along (for now anyway).
    
    # put stuff in the dictionary
    for i ∈ 0:(wordsize-1)
        bitpattern_dictionary[i] = a[i+1];
    end
    bitpattern_dictionary # return to caller
end;





S = let
    S = (-1.0)^(d[31]);
end





calculated_significand_value = let

    # initialize -
    calculated_significand_value = 0.0;
    b = 2.0; # binary, base = 2
    msb = 23; # most significant bit (msb)
    lsb = 1; # least significant bit (lsb)
    significand_range_array = range(lsb,stop=msb,step=1) |> collect; # range of bits to use for the significand

    for i ∈ significand_range_array
        calculated_significand_value += (b^(-i))*d[msb-i]
    end
    calculated_significand_value + 1
end





@assert significand(x) == calculated_significand_value # compare built-in versus our calculated value





E = let

    # initialize -
    calculated_exponent_value = 0.0;
    b = 2.0; # binary, base = 2
    msb = 30; # most significant bit (msb)
    lsb = 23; # least significant bit (lsb)
    exponent_bit_range_array = range(lsb, stop=msb, step = 1) |> collect

    for i ∈ eachindex(exponent_bit_range_array)
        j = exponent_bit_range_array[i]; # remap operation
        calculated_exponent_value += d[j]*(b^(i - 1)) # why -1?
    end
    calculated_exponent_value
end;





@assert S*(calculated_significand_value)*2^(E - 127) == x # If this doesn't blow up, nice!





max_significand_value = let

    # initialize -
    d = Dict{Int64, Int64}(); 
    calculated_significand_value = 0.0;
    b = 2.0; # binary, base = 2
    msb = 23; # most significant bit (msb)
    lsb = 1; # least significant bit (lsb)
    significand_range_array = range(lsb,stop=msb,step=1) |> collect; # range of bits to use for the significand

    # all ones, gives max 
    number_of_digits = length(significand_range_array); # how many digits do we have for the significand?
    max_digits_array = ones(number_of_digits); # max case: our digits array will be all ones
    for i ∈ 1:number_of_digits
        d[i-1] = 1.0;
    end

    for i ∈ significand_range_array
        calculated_significand_value += (b^(-i))*d[msb-i]
    end
    calculated_significand_value + 1
end






